{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>Exploring some derived features to improve regression via ML Models</h1>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook we will explore some feature engineering of the raw features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from src.data import replace_mod, load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(\"../data/Peptides_and_iRT.tsv\")\n",
    "data.fillna(-1).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct more features:\n",
    "\n",
    "For the sequences, we will look at the counts of every type of amino acid in the sequence. \n",
    "\n",
    "To further incorporate information about the modifications, we include at which position in the peptide the modification occurs (beyond the information if/how many modifications occur).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_index = data.query(\"is_mod == 1\").index\n",
    "re_mod = re.compile(r\"\\[([\\+A-Za-z0-9]+)\\]\")\n",
    "data.loc[mod_index, \"modification\"] = data.query(\"is_mod == 1\")[\"sequence_raw\"].str.findall(re_mod)\n",
    "\n",
    "data.loc[mod_index, \"modification_num\"] = data.loc[mod_index, \"modification\"].apply(len)\n",
    "data.loc[mod_index, \"modification_loc\"] = data.query(\"is_mod == 1\")[\"sequence_raw\"].apply(lambda s: [match.span()[0] for match in re.finditer(re_mod,s)])\n",
    "\n",
    "max_mod = data.loc[mod_index, \"modification_loc\"].apply(len).max()\n",
    "for m in range(max_mod):\n",
    "    data.loc[mod_index, f\"modification_loc_{m + 1}\"] = data.loc[mod_index, \"modification_loc\"].apply(lambda l: l[m] if len(l) > m  else -1)\n",
    "    data.loc[mod_index, f\"modification_type_{m + 1}\"] = data.loc[mod_index, \"modification\"].apply(lambda l: l[m] if len(l) > m else \"\")\n",
    "\n",
    "    data.loc[:, f\"modification_type_{m+1}\"] = data.loc[:, f\"modification_type_{m+1}\"].fillna(\"\").astype(\"category\").cat.codes\n",
    "\n",
    "data.fillna(-1).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_types = list(f\"[{s}]\" for s in data.query(\"is_mod == 1\")[\"modification\"].explode().unique() if len(s) > 0)\n",
    "data.loc[:, \"sequence_proc\"] =  data.loc[:, \"sequence_raw\"].apply(lambda s: replace_mod(s, mod_types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Tfidf and count vectorizers, inspect AA frequencies and occurences in documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = data[\"sequence_proc\"].explode().unique()\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(token_pattern=r\"(?u)\\b\\w\\d?\\b\", vocabulary=list(vocabulary), lowercase=False)\n",
    "vec.fit_transform(data[\"sequence_proc\"].apply(lambda s: \" \".join(s)).to_numpy()).toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w\\d?\\b\", vocabulary=list(vocabulary), lowercase=False)\n",
    "tfidf.fit_transform(data[\"sequence_proc\"].apply(lambda s: \" \".join(s)).to_numpy()).toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "pd.DataFrame(zip(tfidf.vocabulary, 1 / tfidf.idf_), columns=[\"Amino Acid\", \"doc frequency\"]). \\\n",
    "    sort_values(\"doc frequency\", ascending=False).plot.bar(x=\"Amino Acid\", figsize=(8,8), color=\"darkred\", rot=45, legend=False)\n",
    "\n",
    "\n",
    "plt.title(\"Amino Acid document frequencies\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessment of vectorizers: Which vectorization produces stronger correlations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, [f\"AAcount_{v}\" for v in vocabulary]] = vec.fit_transform(data[\"sequence_proc\"].apply(lambda s: \" \".join(s)).to_numpy()).toarray()\n",
    "\n",
    "\n",
    "feat_correlations = data.fillna(-1).corr(method=\"pearson\")\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(feat_correlations,\n",
    "           square=True,\n",
    "           center=0,\n",
    "           annot=np.round(feat_correlations,2),\n",
    "           fmt=\"\",\n",
    "           linewidths=.5,\n",
    "           cmap=\"vlag\",\n",
    "           cbar_kws={\"shrink\": 0.8})\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tfidf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, [f\"AAcount_{v}\" for v in vocabulary]] = tfidf.fit_transform(data[\"sequence_proc\"].apply(lambda s: \" \".join(s)).to_numpy()).toarray()\n",
    "\n",
    "\n",
    "feat_correlations = data.fillna(-1).corr(method=\"pearson\")\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(feat_correlations,\n",
    "           square=True,\n",
    "           center=0,\n",
    "           annot=np.round(feat_correlations,2),\n",
    "           fmt=\"\",\n",
    "           linewidths=.5,\n",
    "           cmap=\"vlag\",\n",
    "           cbar_kws={\"shrink\": 0.8})\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "We see that the count vectorizer produces stronger correlation patterns between iRT and AA types. While this does not preclude the utility of Tfidf for the regression task, it is a first hint that count vectorization will produce more expressive features. \n",
    "\n",
    "\n",
    "### Code export:\n",
    "\n",
    "The results of this notebook have been written to `src/data/preprocess.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('biognosys')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "7eaae0a3819f9c24bdd2f13cf6f8ff7c943e8ce1e4be6c4dc6c10c30cd9c8dc8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
