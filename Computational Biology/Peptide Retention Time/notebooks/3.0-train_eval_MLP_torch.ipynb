{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>Multi-layer perceptron</h1>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "As an example for a deep learning model, but keeping the computational requirements as minimal as possible, we will train and evaluate a MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import torch\n",
    "import mlflow\n",
    "mlflow.autolog()\n",
    "mlflow.set_experiment(\"Peptide retention time regression\")\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from src.data import load_data, preprocess_data, PeptideDataset\n",
    "from src.models import LGBMModelHandler\n",
    "from src.util import  rMAE, rMSE\n",
    "from src.models import  MLP, TorchModelHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the MLP and a model handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(\"../data/Peptides_and_iRT.tsv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpHandler = TorchModelHandler(MLP, \n",
    "                               data=data, \n",
    "                               val_frac=0.15, \n",
    "                               test_frac=0.15, \n",
    "                               vectorizer=CountVectorizer, \n",
    "                               model_parameters=dict(hidden_dim=128, \n",
    "                                                     hidden_layers=3, \n",
    "                                                     output_dim=1, \n",
    "                                                     dropout_prob=0.3)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpHandler.train_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpHandler.eval(mlpHandler.test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = mlpHandler.predict_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "y_true, y_pred = pred.T\n",
    "\n",
    "sns.scatterplot(y_true, y_pred , marker='+', color=\"darkred\")\n",
    "\n",
    "plt.plot([-100,150], [-100, 150], color=\"black\", lw=0.75)\n",
    "\n",
    "plt.xlabel(\"iRT measured\")\n",
    "plt.ylabel(\"iRT predicted\")\n",
    "\n",
    "\n",
    "plt.title(\"MLP predictions vs. GT\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpHandler.dump(\"../models/mlp.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpHandler.load(\"../models/mlp.pth\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "Conclusions\n",
    "</h1>\n",
    "\n",
    "The MLP does not perform on par with the LightGBM model (not very surprising to me). The model has not been tuned, or trained for very long due to limited resources, so there might be some room for improvement at the expense of training time and model size. For tabular data such as this, LightGBM is usually an excellent choice both in terms of accuracy and resource efficiency.\n",
    "\n",
    "Note that the saving and loading has not been implemented with mlflow since this requires pytorch-lightning. In the interest of keeping this a lightweight project, I did not include it in the environment. Instead the model can be saved and loaded from the model handler.\n",
    "\n",
    "You can load the model using the modelHandlers `load` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "b08f30121e66749dcbc3b1dd36e6e44a5a3035b66bc0d408f96eaf475ebf976d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
